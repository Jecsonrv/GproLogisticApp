# MIGRACI√ìN A POSTGRESQL + REDIS

## Resumen de Cambios

Esta migraci√≥n prepara GPRO Logistic para producci√≥n con:

1. **PostgreSQL** - Base de datos robusta con transacciones ACID
2. **Redis** - Cache distribuido, sesiones r√°pidas y locks
3. **Locks Distribuidos** - Prevenci√≥n de condiciones de carrera en operaciones financieras

---

## üöÄ Inicio R√°pido

### 1. Iniciar servicios con Docker

```bash
cd backend

# Iniciar PostgreSQL y Redis
docker-compose up -d

# Verificar que est√°n corriendo
docker-compose ps
```

### 2. Configurar variables de entorno

Crear archivo `.env` en `/backend/`:

```env
# Copiar de .env.example
ENVIRONMENT=development
DATABASE_ENGINE=postgresql
REDIS_ENABLED=True

# Base de datos
DB_NAME=gpro_logistic
DB_USER=postgres
DB_PASSWORD=gpro_secure_2024
DB_HOST=localhost
DB_PORT=5432

# Redis
REDIS_URL=redis://localhost:6379
```

### 3. Migrar la base de datos

```bash
# Crear las tablas en PostgreSQL
python manage.py migrate

# Crear superusuario
python manage.py createsuperuser
```

### 4. Verificar infraestructura

```bash
python manage.py check_infra
```

Resultado esperado:

```
==================================================
 GPRO Logistic - Infrastructure Health Check
==================================================

üì¶ DATABASE
------------------------------
   Engine: PostgreSQL
   Database: gpro_logistic
   Host: localhost
   Status: ‚úì Connected (5.2ms)

üíæ CACHE (Redis)
------------------------------
   Backend: Redis
   URL: redis://localhost:6379
   Default Cache: ‚úì Connected (1.1ms)
   Locks Cache: ‚úì Connected

 ‚úì All systems operational
```

---

## üìã Arquitectura de Infraestructura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    GPRO Logistic App                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Frontend   ‚îÇ  ‚îÇ   Django    ‚îÇ  ‚îÇ  Background Tasks   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   (React)   ‚îÇ‚îÄ‚îÄ‚îÇ    API      ‚îÇ‚îÄ‚îÄ‚îÇ    (Celery*)        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                          ‚îÇ                                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                          ‚îÇ                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                   INFRAESTRUCTURA                      ‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
‚îÇ  ‚îÇ                         ‚îÇ                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ   PostgreSQL    ‚îÇ   ‚îÇ   ‚îÇ       Redis         ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ                 ‚îÇ   ‚îÇ   ‚îÇ                     ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ  ‚Ä¢ √ìrdenes      ‚îÇ   ‚îÇ   ‚îÇ  db0: Cache general ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ  ‚Ä¢ Facturas     ‚îÇ   ‚îÇ   ‚îÇ  db1: Locks         ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ  ‚Ä¢ Clientes     ‚îÇ   ‚îÇ   ‚îÇ  db2: Sesiones      ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ  ‚Ä¢ Usuarios     ‚îÇ   ‚îÇ   ‚îÇ                     ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                         ‚îÇ                             ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîí Locks Distribuidos

### ¬øPor qu√© son necesarios?

En un ERP con m√∫ltiples usuarios, dos operativos podr√≠an intentar:

-   Facturar la **misma orden** al mismo tiempo
-   Registrar pagos simult√°neos en la **misma factura**
-   Aplicar notas de cr√©dito concurrentemente

Sin locks, esto causa:

-   Doble facturaci√≥n
-   Saldos incorrectos
-   Datos corruptos

### Operaciones Protegidas

| Operaci√≥n      | Lock Key                           | Timeout |
| -------------- | ---------------------------------- | ------- |
| Crear factura  | `invoice_os_{service_order_id}`    | 30s     |
| Registrar pago | `invoice_payment_{invoice_id}`     | 30s     |
| Aplicar NC     | `invoice_credit_note_{invoice_id}` | 30s     |

### Uso en el C√≥digo

```python
from apps.core.cache import distributed_lock, LockAcquisitionError

# Opci√≥n 1: Context Manager
with distributed_lock(f'facturar_os_{order_id}', timeout=30):
    # Solo un proceso puede ejecutar esto
    crear_factura(order_id)

# Opci√≥n 2: Decorador
@distributed_lock('operacion_critica')
def mi_operacion():
    pass

# Manejo de errores
try:
    with distributed_lock('mi_lock'):
        proceso_critico()
except LockAcquisitionError:
    return Response(
        {'error': 'Otro usuario est√° procesando esta operaci√≥n'},
        status=409  # Conflict
    )
```

---

## üíæ Sistema de Cache

### Caches Disponibles

| Cache      | Base Redis | Prop√≥sito           | Timeout Default |
| ---------- | ---------- | ------------------- | --------------- |
| `default`  | db0        | M√©tricas, consultas | 5 minutos       |
| `locks`    | db1        | Locks distribuidos  | Sin timeout     |
| `sessions` | db2        | Sesiones de usuario | 24 horas        |

### Uso del Cache Manager

```python
from apps.core.cache import CacheManager

cache = CacheManager()

# Guardar
cache.set('dashboard_metrics', data, timeout=300)

# Obtener
data = cache.get('dashboard_metrics')

# Invalidar
cache.delete('dashboard_metrics')

# Con patr√≥n
cache.delete_pattern('dashboard_*')
```

### Comandos de Gesti√≥n

```bash
# Limpiar todo el cache
python manage.py clearcache --all

# Solo dashboard
python manage.py clearcache --dashboard

# Solo locks (¬°cuidado!)
python manage.py clearcache --locks

# Por patr√≥n
python manage.py clearcache --pattern="invoice_*"
```

---

## üêò PostgreSQL

### Configuraci√≥n Optimizada

```python
# settings.py
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'gpro_logistic',
        'CONN_MAX_AGE': 60,  # Conexiones persistentes
        'OPTIONS': {
            'options': '-c statement_timeout=30000',  # 30s max/query
        },
    }
}
```

### Migraciones desde SQLite

```bash
# 1. Exportar datos de SQLite
python manage.py dumpdata --exclude=contenttypes > backup.json

# 2. Cambiar a PostgreSQL en .env
DATABASE_ENGINE=postgresql

# 3. Crear tablas
python manage.py migrate

# 4. Importar datos
python manage.py loaddata backup.json
```

---

## üê≥ Docker Compose

### Servicios

```yaml
services:
    postgres: # Puerto 5432
    redis: # Puerto 6379
    pgadmin: # Puerto 5050 (solo con profile 'tools')
    redis-commander: # Puerto 8082 (solo con profile 'tools')
```

### Comandos √ötiles

```bash
# Solo base de datos y cache
docker-compose up -d

# Con herramientas de admin
docker-compose --profile tools up -d

# Ver logs
docker-compose logs -f postgres
docker-compose logs -f redis

# Reiniciar todo
docker-compose down && docker-compose up -d

# Eliminar vol√∫menes (¬°borra datos!)
docker-compose down -v
```

### Acceso a PgAdmin

1. Ir a http://localhost:5050
2. Login: admin@gpro.com / admin123
3. Add Server:
    - Name: GPRO Local
    - Host: postgres
    - Port: 5432
    - User: postgres
    - Password: gpro_secure_2024

---

## ‚ö†Ô∏è Troubleshooting

### Error: Connection refused (PostgreSQL)

```bash
# Verificar que el contenedor est√° corriendo
docker-compose ps

# Reiniciar
docker-compose restart postgres
```

### Error: Redis connection failed

```bash
# Verificar Redis
docker-compose exec redis redis-cli ping
# Deber√≠a responder: PONG
```

### Error: Lock could not be acquired

```bash
# Limpiar locks hu√©rfanos
python manage.py clearcache --locks

# O desde Redis directamente
docker-compose exec redis redis-cli -n 1 FLUSHDB
```

### Error: Cache not working

```python
# Verificar en Python shell
python manage.py shell

from django.core.cache import caches
cache = caches['default']
cache.set('test', 'ok', 10)
print(cache.get('test'))  # Deber√≠a imprimir 'ok'
```

---

## üìä Monitoreo

### Health Check Endpoint

```bash
curl http://localhost:8000/api/health/
```

### M√©tricas de Redis

```bash
# Info general
docker-compose exec redis redis-cli INFO

# Memoria usada
docker-compose exec redis redis-cli INFO memory

# Keys por base de datos
docker-compose exec redis redis-cli INFO keyspace
```

### Conexiones PostgreSQL

```sql
-- En PgAdmin o psql
SELECT count(*) FROM pg_stat_activity WHERE datname = 'gpro_logistic';
```

---

## üîÑ Rollback a SQLite (Emergencia)

Si necesitas volver a SQLite temporalmente:

```env
# .env
DATABASE_ENGINE=sqlite
REDIS_ENABLED=False
```

El sistema autom√°ticamente usar√°:

-   SQLite (`db.sqlite3`)
-   Cache en memoria local
-   Sin locks distribuidos (solo DB locks)

---

## üìÅ Archivos Modificados/Creados

| Archivo                                        | Cambio                    |
| ---------------------------------------------- | ------------------------- |
| `config/settings.py`                           | PostgreSQL + Redis config |
| `requirements.txt`                             | Nuevas dependencias       |
| `docker-compose.yml`                           | **Nuevo** - Servicios     |
| `.env.example`                                 | **Nuevo** - Variables     |
| `apps/core/cache.py`                           | **Nuevo** - Locks & cache |
| `apps/orders/views_invoices.py`                | Locks en operaciones      |
| `apps/dashboard/views.py`                      | Cache en m√©tricas         |
| `apps/core/management/commands/clearcache.py`  | **Nuevo**                 |
| `apps/core/management/commands/check_infra.py` | **Nuevo**                 |

---

## ‚úÖ Checklist de Despliegue

-   [ ] Docker instalado
-   [ ] `docker-compose up -d` ejecutado
-   [ ] `.env` configurado
-   [ ] `python manage.py migrate` ejecutado
-   [ ] `python manage.py check_infra` pasa
-   [ ] Frontend conecta correctamente
-   [ ] Prueba de facturaci√≥n funciona
-   [ ] Prueba de pago funciona
